# -*- coding: utf-8 -*-
"""predict exam score from study hours

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DSVV5BRe_M8Isew_KdizGGin2l9mDgwb

# 1. Import Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

""" # 2. Load the Dataset


"""

df = pd.read_csv('NELS.csv')
df.head()

df.info()
df.describe()
df.isnull().sum()  # Check missing values

"""# Data Visualization & Exploration"""

# Histogram for numeric features
df.hist(figsize=(18, 15), bins=30, edgecolor='black')
plt.tight_layout()
plt.show()

plt.figure(figsize=(15,10))
sns.heatmap(df.corr(), cmap="coolwarm", annot=False)
plt.title("Correlation Heatmap")
plt.show()

"""# Feature Engineering & Encoding"""

import pandas as pd
from sklearn.preprocessing import StandardScaler

# --- 1. One-hot encode categorical variables ---
categorical_cols = ["SEX", "RACE", "HSSTAT", "F4HSTYPE"]

# drop_first=True â†’ avoids dummy variable trap
df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

print("âœ… One-hot encoding done. New shape:", df_encoded.shape)

# --- 2. Standardize numerical features ---
scaler = StandardScaler()
scaled_data = scaler.fit_transform(df_encoded)

# Convert back to DataFrame for easier handling
df_scaled = pd.DataFrame(scaled_data, columns=df_encoded.columns)

print("âœ… Scaling done. Final dataset shape:", df_scaled.shape)

# Now df_scaled is ready for clustering

target = "F22XMSTD"
# Pairplot with exam score
sns.pairplot(df[[target, "BY2XRSTD", "BY2XMSTD", "BY2XSSTD", "BY2XHSTD"]])
plt.show()

# Boxplot: categorical vs exam score
# Use df_encoded for boxplots as categorical features were one-hot encoded
sns.boxplot(x="SEX_2", y=target, data=df_encoded) #  SEX_2 is one of the encoded columns
plt.show()

"""#Prediction Model"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# ðŸŽ¯ Step 1: Define target + features
target = "F22XMSTD"   # replace with your grade column name
X = df.drop(columns=[target])  # features
y = df[target]                # target

# ðŸŽ¯ Step 2: Train/Test Split (80/20 split)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ðŸŽ¯ Step 3: Train a baseline model (Linear Regression)
lr = LinearRegression()
lr.fit(X_train, y_train)

# ðŸŽ¯ Step 4: Predictions
y_pred = lr.predict(X_test)

# ðŸŽ¯ Step 5: Evaluate model
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print("ðŸ“Š Baseline Model (Linear Regression)")
print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"RÂ²: {r2:.2f}")

"""### polynomial regression"""

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Create polynomial regression pipeline (degree=2 as start)
poly_model = Pipeline([
    ("poly_features", PolynomialFeatures(degree=2, include_bias=False)),
    ("lin_reg", LinearRegression())
])

# Fit model
poly_model.fit(X_train, y_train)

# Predictions
y_pred_poly = poly_model.predict(X_test)

# Evaluation
mae = mean_absolute_error(y_test, y_pred_poly)
rmse = np.sqrt(mean_squared_error(y_test, y_pred_poly))
r2 = r2_score(y_test, y_pred_poly)

print("Polynomial Regression (degree=3)")
print("MAE:", mae)
print("RMSE:", rmse)
print("RÂ²:", r2)

# Step 1: Correlation with target
target = "F22XMSTD"
corr_matrix = df.corr()

# Get correlations with target, sorted by absolute value
corr_with_target = corr_matrix[target].abs().sort_values(ascending=False)
print(corr_with_target)

# Step 2: Pick features with correlation > threshold (e.g. 0.3)
selected_features = corr_with_target[corr_with_target > 0.3].index.drop(target)
print("Selected Features:", selected_features)

# Step 3: Use only those features
X = df[selected_features]
y = df[target]

# Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Train model
lr = LinearRegression()
lr.fit(X_train, y_train)

# Predictions & evaluation
y_pred = lr.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print("\nðŸ“Š Correlation-Filtered Model")
print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"RÂ²: {r2:.2f}")

from sklearn.ensemble import RandomForestRegressor
import pandas as pd
import numpy as np

# ðŸŽ¯ Target (math score)
target = "F22XMSTD"
X = df.drop(columns=[target])
y = df[target]

# Train/test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- Train a Random Forest for feature importance ---
rf = RandomForestRegressor(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)

# Get feature importances
importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)

print("ðŸ”¥ Top 15 Important Features from RandomForest:")
print(importances.head(15))

# --- Select top k features ---
top_k = 15
selected_features = importances.head(top_k).index

X_train_sel = X_train[selected_features]
X_test_sel = X_test[selected_features]

# --- Train a Linear Regression on selected features ---
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

lr = LinearRegression()
lr.fit(X_train_sel, y_train)
y_pred = lr.predict(X_test_sel)

mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print("\nðŸ“Š Tree-Based Feature Selected Model (Linear Regression)")
print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"RÂ²: {r2:.2f}")

